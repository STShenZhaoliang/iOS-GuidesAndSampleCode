## 1.Providing Haptic Feedback
提供触觉反馈
On iPhone 7 and iPhone 7 Plus, haptics provide additional ways to physically engage users with tactile feedback that gets attention and reinforces actions. Some system-provided interface elements, such as pickers, switches, and sliders, automatically provide haptic feedback as users interact with them.

在iPhone 7和iPhone 7 Plus上，触觉提供了更多的方式来吸引用户的触觉反馈，从而吸引观众并强化行动。 一些系统提供的界面元素，如选择器，开关和滑块，随着用户与它们的交互，自动提供触觉反馈。

To give you the ability to generate haptics in an app that targets iOS 10, UIKit introduces the new 
`UIFeedbackGenerator` class and three concrete subclasses, each of which enables haptics that are 
appropriate for a specific scenario, as shown in Table 1.

为了让您能够在面向iOS 10的应用中生成触觉，UIKit引入了新的功能
`UIFeedbackGenerator`类和三个具体的子类，每个都有触觉
适用于特定场景，如表1所示。

Table 1  Concrete feedback generator classes and example usages

| Class name | Example usage |
| --- | --- |
|  UIImpactFeedbackGenerator| Provides a physical experience that complements the visual feedback for an action or task. For example, the user might feel a thud when a view slides into place or two objects collide. |
| UINotificationFeedbackGenerator |  Indicates that a task or action, such as depositing a check or unlocking a vehicle, has completed, failed, or produced a warning of some kind.|
| UISelectionFeedbackGenerator | Indicates that the selection is actively changing. For example, the user feels light taps while scrolling a picker wheel. |

表1具体的反馈发生器类和示例用法

| 类名| 使用示例|
| --- | --- |
|UIImpactFeedbackGenerator| 提供补充动作或任务的视觉反馈的物理体验。 例如，当视图滑动到位或两个对象碰撞时，用户可能会感到重击。|
| UINotificationFeedbackGenerator | 表示一项任务或行动，例如存放支票或解锁车辆，已完成，失败或产生某种类型的警告。
| UISelectionFeedbackGenerator | 表示选择正在主动更改。 例如，当滚动选择轮时，用户感觉到轻拍。|


Using one of the concrete subclasses, you ask the system to generate haptics for a specific scenario and iOS manages the strength and behavior of the feedback based on the scenario you choose. In addition, you can call the prepare method of UIFeedbackGenerator to inform the system that haptic feedback is about to be required and to minimize latency. To learn how to use haptics to provide the best user experience in your app, see “Haptic Feedback” in iOS Human Interface Guidelines.

使用其中一个具体的子类，您可以要求系统为特定场景生成触觉，而iOS会根据您选择的场景来管理反馈的强度和行为。 此外，您可以调用UIFeedbackGenerator的prepare方法通知系统即将要求触觉反馈并最小化延迟。 要了解如何使用触觉来提供应用程序中最佳的用户体验，请参阅iOS人机接口指南中的“触觉反馈”。

## 2.SiriKit

Apps that provide services in specific domains can use SiriKit to make those services available from Siri on iOS. Making your services available requires creating one or more app extensions using the Intents and Intents UI frameworks. SiriKit supports services in the following domains:

在特定域中提供服务的应用程序可以使用SiriKit在iOS上从Siri提供这些服务。 使您的服务可用需要使用Intents和Intents UI框架创建一个或多个应用程序扩展。 SiriKit支持以下领域的服务：

1. Audio or video calling （音频或视频通话）

2. Messaging （消息）

3. Sending or receiving payments （发送或接收付款）

4. Searching photos （搜索照片）

5. Booking a ride （预订车）

6. Managing workouts （管理锻炼）

7. Adjusting settings in a CarPlay-enabled vehicle (automotive vendors only) 在启用CarPlay的车辆中调整设置（仅限汽车供应商）

8. Making restaurant reservations (requires additional support from Apple) 预订餐厅（需要苹果的额外支持）

When the user makes a request involving your service, SiriKit sends your extension an intent object, which describes the user’s request and provides any data related to that request. You use the intent object to provide an appropriate response object, which includes details of how you can handle the user’s request. Siri typically handles all user interactions, but you can use an extension to provide custom UI that incorporates branding or additional information from your app.

当用户提出涉及您的服务的请求时，SiriKit将您的扩展名发送到一个intent对象，该对象描述用户的请求，并提供与该请求相关的任何数据。 您使用intent对象来提供适当的响应对象，其中包含如何处理用户请求的详细信息。 Siri通常处理所有用户交互，但您可以使用扩展程序来提供自定义UI，其中包含来自应用程序的品牌或附加信息。

SiriKit also provides a mechanism you can use to tell the system about the interactions and activities that occur within your app. SiriKit defines an interaction object, which combines an intent with information about the intent-handling process, including details such as the start time and duration of a specific occurrence of the process. If your app is registered as capable of handling an activity that has the same name as an intent, the system can launch your app with an interaction object containing that intent even if you don’t provide an Intents app extension.

SiriKit还提供了一种机制，可用于告诉系统有关应用程序中发生的交互和活动。 SiriKit定义了一个交互对象，它将意图与意图处理过程的信息相结合，包括特定事件发生的开始时间和持续时间等细节。 如果您的应用程序注册为能够处理与意图相同名称的活动，则即使您没有提供Intents应用程序扩展名，系统也可以使用包含该意图的交互对象启动应用。

Ride booking is supported by both Maps and Siri, and users can also make restaurants reservations with Maps. Your Intents extension handles interactions that originate from the Maps app in the same way that it handles requests coming from Siri. If you customize the user interface, your Intents UI extension can also configure itself differently, depending on whether the request came from Siri or Maps.

地图和Siri都支持骑行预订，用户还可以使用Google地图预订餐厅。 您的Intents扩展程序以与处理来自Siri的请求相同的方式处理来自Maps应用程序的交互。 如果您自定义用户界面，则Intents UI扩展还可以以不同方式进行配置，具体取决于请求是来自Siri还是Maps。

To learn how to support SiriKit and give users new ways to access your services, read SiriKit Programming Guide. When you’re ready to implement the app extensions that handle various intents, see Intents Framework Reference and Intents UI Framework Reference.

要了解如何支持SiriKit并为用户提供访问您的服务的新方法，请阅读SiriKit编程指南。 当您准备好实现处理各种意图的应用程序扩展时，请参阅Intents Framework Reference和Intents UI Framework Reference。

## 3.Proactive Suggestions

积极的建议

iOS 10 introduces new ways to increase engagement with your app by helping the system suggest your app to users at appropriate times. If you adopted app search in your iOS 9 app, you gave users access to activities and content deep within your app through Spotlight and Safari search results, Handoff, and Siri suggestions. In iOS 10 and later, you can provide information about what users do in your app, which helps the system promote your app in additional places, such as the keyboard with QuickType suggestions, Maps and CarPlay, the app switcher, Siri interactions, and (for media playing apps) the lock screen. These opportunities for enhanced integration with the system are supported by a collection of technologies, such as NSUserActivity, web markup defined by Schema.org, and APIs defined in the Core Spotlight, MapKit, UIKit, and Media Player frameworks.

iOS 10通过帮助系统在适当的时间向用户建议您的应用，引入了新的方法来增加与您的应用的互动。 如果您在iOS 9应用程序中采用了应用程序搜索，则可以通过Spotlight和Safari搜索结果，Handoff和Siri建议，让用户访问您应用程序内的活动和内容。 在iOS 10及更高版本中，您可以提供有关用户在应用中执行的操作的信息，这有助于系统在其他地方宣传您的应用，例如带有QuickType建议的键盘，地图和CarPlay，应用切换器，Siri互动和（ 用于媒体播放应用程序）锁屏。 这些增强与系统集成的机会得到了诸如NSUserActivity，由Schema.org定义的Web标记以及Core Spotlight，MapKit，UIKit和Media Player框架中定义的API等技术的支持。

In iOS 10, the NSUserActivity object includes the mapItem property, which lets you provide location information that can be used in other contexts. For example, if your app displays hotel reviews, you can use the mapItem property to hold the location of the hotel the user is viewing so that when the user switches to a travel planning app, that hotel’s location is automatically available. And if you support app search, you can use the new text-based address component properties in CSSearchableItemAttributeSet, such as thoroughfare and postalCode, to fully specify locations to which the user may want to go. Note that when you use the mapItem property, the system automatically populates the contentAttributeSet property, too.

在iOS 10中，NSUserActivity对象包括mapItem属性，可以让您提供可在其他上下文中使用的位置信息。 例如，如果您的应用程序显示酒店评论，您可以使用mapItem属性来保存用户正在查看的酒店的位置，以便当用户切换到旅行计划应用程序时，该酒店的位置可以自动使用。 如果您支持应用程序搜索，则可以使用CSSearchableItemAttributeSet中的新的基于文本的地址组件属性（如通行和邮政编码）来完全指定用户可能要去的位置。 请注意，当您使用mapItem属性时，系统也会自动填充contentAttributeSet属性。

To share a location with the system, be sure to specify latitude and longitude values, in addition to values for the address component properties in CSSearchableItemAttributeSet. It’s also recommended that you supply a value for the namedLocation property, so that users can view the name of the location, and the phoneNumbers property, so that users can use Siri to initiate a call to the location.

要与系统共享位置，除了CSSearchableItemAttributeSet中的地址组件属性的值之外，请务必指定纬度和经度值。 还建议您为namedLocation属性提供一个值，以便用户可以查看位置名称和phoneNumbers属性，以便用户可以使用Siri启动对该位置的呼叫。

In iOS 9, adding markup to the structured data on your website enriched the content that users see in Spotlight and Safari search results. In iOS 10, you can use location-related vocabulary defined at Schema.org, such as PostalAddress, to further enhance the user’s experience. For example, if users view a location described on your website, the system can suggest the same location when users switch to Maps. Note that Safari supports both JSON-LD and Microdata encodings of Schema.org vocabularies.

在iOS 9中，为您网站上的结构化数据添加标记，丰富了用户在Spotlight和Safari搜索结果中看到的内容。 在iOS 10中，您可以使用在Schema.org中定义的位置相关词汇，例如PostalAddress，以进一步增强用户体验。 例如，如果用户查看您网站上描述的位置，系统可以在用户切换到地图时建议相同的位置。 请注意，Safari支持Schemaorg词汇表的JSON-LD和Microdata编码。

UIKit introduces the textContentType property in the UITextInputTraits protocol so that you can specify the semantic meaning of the content you expect users to enter in a text area. When you provide this information, the system can in some cases automatically select an appropriate keyboard and improve keyboard corrections and proactive integration with information supplied from other apps and websites. For example, if you use UITextContentTypeFullStreetAddress to tell the system that you expect users to enter a complete address in a text field, the system can suggest the address of a location the user was recently viewing.

UIKit在UITextInputTraits协议中引入textContentType属性，以便您可以指定期望用户在文本区域中输入的内容的语义含义。 当您提供此信息时，系统在某些情况下可以自动选择适当的键盘，并改进键盘更正并主动集成其他应用程序和网站提供的信息。 例如，如果您使用UITextContentTypeFullStreetAddress告诉系统您希望用户在文本字段中输入完整的地址，系统可以建议用户最近查看的位置的地址。

If your app plays media and you use the MPPlayableContentManager APIs, iOS 10 helps you let users view album art and play media through your app on the lock screen.

如果您的应用程序播放媒体并使用MPPlayableContentManager API，则iOS 10可帮助您让用户通过锁定屏幕上的应用查看专辑封面和播放媒体。

If your ride-sharing app uses the MKDirectionsRequest API, iOS 10 can display it in the app switcher when the user is likely to want a ride. To register as a ride-share provider, specify the MKDirectionsModeRideShare value for the MKDirectionsApplicationSupportedModes key in your Info.plist file. If your app supports only ride sharing, the system suggests your app with text that begins “Get a ride to...”; if your app supports both ride sharing and another routing type (such as Automobile or Bike), the system uses the text “Get directions to...”. Note that the MKMapItem object you receive may not include latitude and longitude information and would require geocoding.

如果您的旅行共享应用程序使用MKDirectionsRequest API，则当用户可能需要乘车时，iOS 10可以将其显示在应用程序切换器中。 要注册为共享提供程序，请在Info.plist文件中指定MKDirectionsApplicationSupportedModes项的MKDirectionsModeRideShare值。 如果您的应用程序仅支持乘车共享，系统会建议您的应用程序的文本开始于“乘坐...”; 如果您的应用程序支持乘车共享和其他路由类型（例如汽车或自行车），系统将使用文本“获取路线...”。 请注意，您收到的MKMapItem对象可能不包括纬度和经度信息，并且需要进行地理编码。

## 4.Integrating with the Messages App

与消息应用程序集成

In iOS 10, you can create app extensions that interact with the Messages app and let users send text, stickers, media files, and interactive messages, including interactive messages that update as each recipient responds to the message. You can also make your publicly accessible images available to the #images app in Messages.

You can create two types of app extensions:

A Sticker pack provides a set of stickers that users can add to their Messages content.

An iMessage app lets you present a custom user interface within the Messages app, create a sticker browser, include text, stickers, and media files within a conversation, and create, send, and update interactive messages.

An iMessage app can also help users search images that you host on your app’s related website while they’re in the Messages app.

You can create a Sticker pack without writing any code: Simply drag images into the Sticker Pack folder inside the Stickers asset catalog in Xcode.

To develop an iMessage app, you use the APIs in the Messages framework (Messages.framework). To learn about the Messages framework, see Messages Framework Reference. For general information about creating app extensions, see App Extension Programming Guide.

The #images app in Messages shows people popular images from public websites. Your publicly accessible images can be included in #images search results after Apple's web crawler, known as Applebot, has scanned your website. To make your public images available in #images, follow these steps:

Implement an iMessage app.

Add the com.apple.developer.associated-domains key to your app’s entitlements. Include a list of the web domains that host the images you want to make searchable. For each domain, specify the spotlight-image-search service in an entry such as spotlight-image-search:yourdomain.com.

Add an apple-app-site-association file to your website. Add a dictionary for the spotlight-image-search service and include your app ID, which is the team ID or app ID prefix, followed by the bundle ID. You can specify up to 500 paths and patterns that should be included for indexing for #images (for some examples of website paths, see the universal links examples in Creating and Uploading the Association File).

Allow crawling by Applebot (to learn more, see About Applebot).

在iOS 10中，您可以创建与Messages应用程序交互的应用程序扩展，并让用户发送文本，贴纸，媒体文件和交互式消息，包括随着每个收件人对消息的响应而更新的交互式消息。您还可以将消息中的#images应用程序的公开访问图像提供给您。

您可以创建两种类型的附加应用信息：

贴纸包提供了一组用户可以添加到其消息内容的贴纸。

iMessage应用程序可让您在Messages应用程序中呈现自定义用户界面，在会话中创建贴纸浏览器，包括文本，贴纸和媒体文件，以及创建，发送和更新交互式消息。

一个iMessage应用程序还可以帮助用户搜索您在应用程序相关网站上托管的图片，而这些图片位于“消息”应用程序中。

您可以创建一个贴纸包，而无需编写任何代码：只需将图像拖放到Xcode中的贴纸资产目录中的贴纸包文件夹中。

要开发一个iMessage应用程序，您可以在Messages框架（Messages.framework）中使用API​​。要了解消息框架，请参阅消息框架参考。有关创建应用程序扩展的一般信息，请参阅App Extension编程指南。

消息中的#images应用程序显示公众网站上的人气图片。 Apple的网络抓取工具（称为Applebot）扫描您的网站后，您可公开访问的图像可以包含在#images搜索结果中。要使#image中的公开图像可用，请按照下列步骤操作：

实施iMessage应用程序

将com.apple.developer.associated-domains键添加到应用程序的权利。包含托管您想要搜索的图像的Web域的列表。对于每个域，请在诸如Spotlight-image-search：yourdomain.com等条目中指定聚光灯图像搜索服务。

在您的网站上添加一个apple-app-site-association文件。为Spotlight-image-search服务添加一个字典，并包含您的应用程序ID，即组ID或应用程序ID前缀，后跟包ID。您可以为#images指定最多包含500条路径和模式，用于索引（对于网站路径的一些示例，请参阅创建和上传关联文件中的通用链接示例）。

允许Applebot抓取（要了解更多信息，请参阅关于Applebot）。

## 5.User Notifications

用户通知

iOS 10 introduces the User Notifications framework (UserNotifications.framework), which supports the delivery and handling of local and remote notifications. You use the classes of this framework to schedule the delivery of local notifications based on specific conditions, such as time or location. Apps and app extensions can use this framework to receive and potentially modify local and remote notifications when they are delivered to the user’s device.

Also introduced in iOS 10, the User Notifications UI framework (UserNotificationsUI.framework) lets you customize the appearance of local and remote notifications when they appear on the user’s device. You use this framework to define an app extension that receives the notification data and provides the corresponding visual representation. Your extension can also respond to custom actions associated with those notifications.

iOS 10引入了用户通知框架（UserNotifications.framework），它支持本地和远程通知的传递和处理。 您可以使用此框架的类根据特定条件（如时间或位置）安排本地通知的传递。 应用程序和应用程序扩展可以使用此框架在本地和远程通知传递到用户的设备时接收并潜在地进行修改。

还在iOS 10中引入了用户通知UI框架（UserNotificationsUI.framework），您可以在用户设备上显示本地和远程通知时自定义外观。 您可以使用此框架定义一个应用程序扩展，它接收通知数据并提供相应的可视化表示。 您的扩展程序还可以响应与这些通知相关联的自定义操作。

## 6.Speech Recognition

语音识别

iOS 10 introduces a new API that supports continuous speech recognition and helps you build apps that can recognize speech and transcribe it into text. Using the APIs in the Speech framework (Speech.framework), you can perform speech transcription of both real-time and recorded audio. For example, you can get a speech recognizer and start simple speech recognition using code like this:

let recognizer = SFSpeechRecognizer()

let request = SFSpeechURLRecognitionRequest(url: audioFileURL)

recognizer?.recognitionTask(with: request, resultHandler: { (result, error) in

print (result?.bestTranscription.formattedString)

})

As with accessing other types of protected data, such as Calendar and Photos data, performing speech recognition requires the user’s permission (for more information about accessing protected data classes, see Security and Privacy Enhancements). In the case of speech recognition, permission is required because data is transmitted and temporarily stored on Apple’s servers to increase the accuracy of recognition. To request the user’s permission, you must add the NSSpeechRecognitionUsageDescription key to your app’s Info.plist file and provide content that describes your app’s usage.

When you adopt speech recognition in your app, be sure to indicate to users when their speech is being recognized so that they can avoid making sensitive utterances at that time.

iOS 10引入了一个新的API，支持连续语音识别，并帮助您构建可识别语音并将其转录成文本的应用程序。在Speech框架（Speech.framework）中使用API​​，您可以执行实时和录制音频的语音转录。例如，您可以使用以下代码获取语音识别器并开始简单的语音识别：

let recognizer = SFSpeechRecognizer()

let request = SFSpeechURLRecognitionRequest(url: audioFileURL)

recognizer?.recognitionTask(with: request, resultHandler: { (result, error) in

print (result?.bestTranscription.formattedString)

})

与访问其他类型的受保护数据（例如日历和照片数据）一样，执行语音识别需要用户的许可（有关访问受保护的数据类的更多信息，请参阅安全和隐私增强）。在语音识别的情况下，需要许可，因为数据被传输并临时存储在苹果的服务器上，以提高识别的准确性。要请求用户的许可，您必须将NSSpeechRecognitionUsageDescription键添加到应用程序的Info.plist文件中，并提供描述应用程序使用情况的内容。

当您在应用程序中采用语音识别时，请务必向用户说明他们的演讲是否被识别，以避免在当时发出敏感的话语。

## 7.Wide Color

扩展颜色

Most graphics frameworks throughout the system, including Core Graphics, Core Image, Metal, and AVFoundation, have substantially improved support for extended-range pixel formats and wide-gamut color spaces. By extending this behavior throughout the entire graphics stack, it is easier than ever to support devices with a wide color display. In addition, UIKit standardizes on working in a new extended sRGB color space, making it easy to mix sRGB colors with colors in other, wider color gamuts without a significant performance penalty.

Here are some best practices to adopt as you start working with Wide Color.

In iOS 10, the UIColor class uses the extended sRGB color space and its initializers no longer clamp raw component values to between 0.0 and 1.0. If your app relies on UIKit to clamp component values (whether you’re creating a color or asking a color for its component values), you need to change your app’s behavior when you link against iOS 10.

When performing custom drawing in a UIView on an iPad Pro (9.7 inch), the underlying drawing environment is configured with an extended sRGB color space.

If your app renders custom image objects, use the new UIGraphicsImageRenderer class to control whether the destination bitmap is created using an extended-range or standard-range format.

If you are performing your own image processing on wide-gamut devices using a lower level API, such as Core Graphics or Metal, you should use an extended range color space and a pixel format that supports 16-bit floating-point component values. When clamping of color values is necessary, you should do so explicitly.

Core Graphics, Core Image, and Metal Performance Shaders provide new options for easily converting colors and images between color spaces.

整个系统中的大多数图形框架，包括Core Graphics，Core Image，Metal和AVFoundation，大大改进了对扩展像素格式和宽色域颜色空间的支持。通过在整个图形堆栈中扩展这种行为，比以往更容易支持具有广泛颜色显示的设备。此外，UIKit还规定了在新的扩展sRGB颜色空间中工作，可以轻松地将sRGB颜色与其他更宽的色域中的颜色混合，而不会造成显着的性能损失。

以下是开始使用Wide Color时采用的最佳做法。

在iOS 10中，UIColor类使用扩展的sRGB颜色空间，其初始化器不再将原始组件值粘贴在0.0和1.0之间。如果您的应用程序依赖于UIKit来钳制组件值（无论您是创建颜色还是为组件值提出颜色），您需要在链接到iOS 10时更改应用的行为。

在iPad Pro（9.7英寸）上的UIView中执行自定义绘图时，底层绘图环境配置有扩展的sRGB颜色空间。

如果您的应用程序呈现自定义图像对象，请使用新的UIGraphicsImageRenderer类来控制是使用扩展范围还是标准范围格式创建目标位图。

如果您使用较低级别的API（如Core Graphics或Metal）在宽域设备上执行自己的图像处理，则应使用扩展范围的颜色空间和支持16位浮点数组件值的像素格式。当需要夹持颜色值时，应明确地进行。

核心图形，核心图像和金属性能着色器提供了在颜色空间之间轻松转换颜色和图像的新选项。

## 8.Adapting to the True Tone Display

适应真实色调显示

The True Tone display uses ambient light sensors to automatically adjust the color and intensity of the display to match the lighting conditions of the current environment. To ensure that your app works well with the standard color shift provided by True Tone, add the new UIWhitePointAdaptivityStyle key to your Info.plist file to describe your app’s primary visual content. For example:

If your app is a photo editing app, color fidelity is more important than automatic adjustment to the environmental white point. In this case, you can use the UIWhitePointAdaptivityStylePhoto style to reduce the strength of True Tone shift applied by the system.

If your app is a reading app, conformance with the environmental white point is helpful to users. In this case, you can use the UIWhitePointAdaptivityStyleReading style to increase the strength of True Tone shift applied by the system.

True Tone显示屏使用环境光传感器自动调整显示屏的颜色和强度，使其与当前环境的照明条件相匹配。 为了确保您的应用程序与True Tone提供的标准颜色偏移良好，请将新的UIWhitePointAdaptivityStyle键添加到Info.plist文件中，以描述应用程序的主要可视内容。 例如：

如果您的应用程序是照片编辑应用程序，则色彩保真比自动调整环境白点更重要。 在这种情况下，您可以使用UIWhitePointAdaptivityStylePhoto样式来减少系统应用的True Tone shift的强度。

如果您的应用程序是阅读应用程序，则符合环境白点对用户有帮助。 在这种情况下，您可以使用UIWhitePointAdaptivityStyleReading样式来增加系统应用的True Tone shift的强度。

## 9.App Search Enhancements

应用搜索增强功能

iOS 10 and the Core Spotlight framework introduce several enhancements to app search:

In-app searching

Search continuation

Crowdsourcing deep link popularity with differential privacy

Visualization of validation results

The new CSSearchQuery class supports in-app searches of content that you index using existing Core Spotlight APIs. Using this API can eliminate the need to maintain your own separate search index and lets you take advantage of Spotlight’s powerful search technology and matching rules to allow users to search for content without leaving your app, just as they do within Mail, Messages, and Notes.

In iOS 9, using search APIs (such as Core Spotlight, NSUserActivity, and web markup) to index content within your app let users search for that content using the Spotlight and Safari search interfaces. In iOS 10, you can use new Core Spotlight symbols to let users continue a search they began in Spotlight when they open your app. To enable this feature, add the CoreSpotlightContinuation key to your Info.plist file, give it the value YES, and update your code to handle an activity continuation of type CSQueryContinuationActionType. The user info dictionary in the NSUserActivity object that you receive in your application:continueUserActivity:restorationHandler: method includes the CSSearchQueryString key, whose value is a string that represents the user’s query.

iOS 10 introduces a differentially private way to help improve the ranking of your app’s content in search results. iOS submits a subset of differentially private hashes to Apple servers as users use your app and as NSUserActivity objects that include a deep link URL and have their eligibleForPublicIndexing property set to YES are submitted to iOS. The differential privacy of the hashes allows Apple to count the frequency with which popular deep links are visited without ever associating a user with a link.

When you test your website markup and deep links using the App Search API Validation tool, it now displays a visual representation of your results, including supported markup, such as that defined at Schema.org. The validation tool can help you see information that the Applebot web crawler has indexed, such as the title, description, URL, and other supported elements. You can access the validation tool here: https://search.developer.apple.com/appsearch-validation-tool. To learn more about supporting deep links and adding markup, see Mark Up Web Content.

To learn how to make your website’s images searchable within the Messages app, see Integrating with the Messages App.

iOS 10和Core Spotlight框架为应用程序搜索引入了几项增强功能：

应用内搜索

搜索延续

众包深度链接流行与差异隐私

验证结果的可视化

新的CSSearchQuery类支持使用现有Core Spotlight API索引的内容的应用内搜索。使用此API可以消除维护您自己独立的搜索索引的需要，让您可以利用Spotlight功能强大的搜索技术和匹配规则，让用户在不离开应用的情况下搜索内容，就像在邮件，邮件和Notes中一样。

在iOS 9中，使用搜索API（如Core Spotlight，NSUserActivity和Web标记）来索引应用中的内容，可让用户使用Spotlight和Safari搜索界面搜索该内容。在iOS 10中，您可以使用新的Core Spotlight符号让用户在他们打开应用程序时继续搜索他们在Spotlight中开始的搜索。要启用此功能，请将CoreSpotlightContinuation键添加到Info.plist文件，给它值YES，然后更新代码以处理CSQueryContinuationActionType类型的活动继续。您在应用程序中收到的NSUserActivity对象中的用户信息字典：continueUserActivity：restoreHandler：method包括CSSearchQueryString键，其值为表示用户查询的字符串。

iOS 10引入了一种不同的私人方式来帮助您提高搜索结果中应用内容的排名。当用户使用您的应用程序并将NSUserActivity对象包含深层链接URL并将其“适用于”的“ForForDirectIndex”属性设置为“是”时，iOS会向Apple服务器提交不同私有哈希的子集。哈希算法的差异隐私允许苹果计算访问流行深层链接的频率，而无需将用户与链接相关联。

当您使用App Search API验证工具测试您的网站标记和深层链接时，它现在将显示您的结果的可视化表示，包括支持的标记，例如在Schema.org中定义的标记。验证工具可以帮助您查看Applebot网页抓取工具已编入索引的信息，例如标题，说明，网址和其他支持的元素。您可以访问验证工具：https：//search.developer.apple.com/appsearch-validation-tool。要了解有关支持深层链接和添加标记的更多信息，请参阅标记Web内容。

要了解如何使您的网站的图像可以在Messages应用程序中搜索，请参阅集成消息应用程序。

## 10.Widget Enhancements

小部件增强功能

iOS 10 introduces a new design for the lock screen, which now displays widgets. To ensure that your widget looks good on any background, you can specify widgetPrimaryVibrancyEffect or widgetSecondaryVibrancyEffect, as appropriate (use these properties instead of the deprecated notificationCenterVibrancyEffect property). In addition, widgets now include the concept of display mode (represented by NCWidgetDisplayMode), which lets you describe how much content is available and allows users to choose a compact or expanded view.

iOS 10为锁定屏幕引入了新的设计，现在显示小部件。 要确保您的窗口小部件在任何后台都看起来不错，您可以根据需要指定widgetPrimaryVibrancyEffect或widgetSecondaryVibrancyEffect（使用这些属性，而不是不推荐使用的notificationCenterVibrancyEffect属性）。 此外，小部件现在包括显示模式（由NCWidgetDisplayMode表示）的概念，它可以让您描述多少内容可用，并允许用户选择紧凑或展开的视图。

## 11.Apple Pay Enhancements

苹果付费增强

In iOS 10, users can make easy and secure payments using Apple Pay from websites and through interaction with Siri and Maps. For developers, iOS 10 introduces new APIs you can use in code that runs in both iOS and watchOS, the ability to support dynamic payment networks, and a new sandbox testing environment.

iOS 10 introduces new APIs that help you incorporate Apple Pay directly into your website. When you support Apple Pay in your website, users browsing with Safari in iOS or macOS can make payments using their cards in Apple Pay on their iPhone or Apple Watch. To learn more, see ApplePay JS Framework Reference.

The PassKit framework (PassKit.framework) introduces APIs that let you support Apple Pay in places where UIKit is not available. Specifically, PKPaymentAuthorizationController and PKPaymentAuthorizationControllerDelegate enable features provided by PKPaymentAuthorizationViewController and its delegate, but don’t require UIKit. Although the new API is required for supporting Apple Pay in watchOS and in certain intents, it’s recommended that you adopt it in all of your code so that you can provide broad Apple Pay support with a single code base. (To learn more about intents and Siri integration, see SiriKit.)

The PassKit framework also adds features that let card issuers present their cards from within their apps. Specifically, the PKPaymentButtonTypeInStore button type lets you display an Apple Pay button for a card and the presentPaymentPass: method lets you programmatically display the card (the presentPaymentPass: method is defined in PKPassLibrary).

When a new payment network becomes available, your app can automatically support the new network without requiring you to modify and recompile your app. The availableNetworks method lets you discover the networks that are available on the user's device at runtime. In addition, the supportedNetworks property is expanded, so that it can take some payment provider names as an argument. Your app then automatically supports any networks that the payment provider supports. To learn more, see https://developer.apple.com/apple-pay/.

iOS 10 introduces a new testing environment that lets you provision test cards directly on the device. The test environment returns encrypted test payment data. To use this environment, follow these steps:

Create a testing iCloud Account at iTunes Connect.

Log into that account on your device.

Set the desired region for testing.

Use test cards listed at https://developer.apple.com/apple-pay/.

Note: When you switch iCloud accounts, the environment switches automatically.

You must still test your payments using actual cards in an production environment.

在iOS 10中，用户可以通过网站和通过与Siri和Google Maps的互动，使用Apple Pay进行简单安全的付款。对于开发人员，iOS 10引入了可以在iOS和WatchOS中运行的代码中使用的新API，支持动态支付网络的功能，以及新的沙箱测试环境。

iOS 10引入了新的API，可帮助您将Apple Pay直接纳入您的网站。当您在自己的网站上支持Apple Pay时，在iOS或MacOS上浏览Safari的用户可以使用iPhone或Apple Watch上的Apple Pay进行付款。要了解更多信息，请参阅ApplePay JS Framework Reference。

PassKit框架（PassKit.framework）引入了可以在UIKit不可用的地方支持Apple Pay的API。具体来说，PKPaymentAuthorizationController和PKPaymentAuthorizationControllerDelegate启用由PKPaymentAuthorizationViewController及其委托提供的功能，但不需要UIKit。虽然需要新的API来支持Apple Pay在watchOS和某些意图中，但建议您在所有代码中采用该API，以便您可以使用单个代码库提供广泛的Apple Pay支持。 （要了解更多关于意图和Siri整合，请参阅SiriKit。）

PassKit框架还增加了功能，让发卡机构在他们的应用程序中显示他们的卡。具体来说，PKPaymentButtonTypeInStore按钮类型允许您显示一张卡的Apple Pay按钮，并且presentPaymentPass：方法允许您以编程方式显示卡（thePaymentPass：方法在PKPassLibrary中定义）。

当新的支付网络可用时，您的应用程序可以自动支持新网络，而无需修改和重新编译应用程序。 availableNetworks方法可以让您在运行时发现用户设备上可用的网络。此外，supportedNetworks属性已展开，因此可以将一些付款提供商名称作为参数。然后，您的应用程序会自动支持付款提供商支持的任何网络。要了解更多信息，请参阅https://developer.apple.com/apple-pay/。

iOS 10引入了一个新的测试环境，可以直接在设备上配置测试卡。测试环境返回加密的测试支付数据。要使用此环境，请按照下列步骤操作：

在iTunes Connect上创建测试iCloud帐户。

在您的设备上登录该帐户。

设置所需的测试区域。

使用https://developer.apple.com/apple-pay/上列出的测试卡。

注意：当您切换iCloud帐户时，环境将自动切换。

您仍然必须使用生产环境中的实际卡测试您的付款。

## 12.Security and Privacy Enhancements

安全和隐私增强

iOS 10 introduces several changes and additions that help you improve the security of your code and maintain the privacy of user data. To learn more about these items, see https://developer.apple.com/security/.

The new NSAllowsArbitraryLoadsInWebContent key for your Info.plist file gives you a convenient way to allow arbitrary web page loads to work while retaining ATS protections for the rest of your app. To learn more about this key, see NSAppTransportSecurity.

The SecKey API includes improvements for asymmetric key generation. Use the SecKey API instead of the deprecated Common Data Security Architecture (CDSA) APIs.

The RC4 symmetric cipher suite is now disabled by default for all SSL/TLS connections, and SSLv3 is no longer supported in the Secure Transports API. It’s recommended that you stop using the SHA-1 and 3DES cryptographic algorithms as soon as possible.

The UIPasteboard class supports the Clipboard feature, which lets users copy and paste between devices, and includes API you can use to restrict a pasteboard to a specific device and set an expiration timestamp after which the pasteboard is cleared. Additionally, named pasteboards are no longer persistent—instead, you should use shared containers—and the “Find” pasteboard (that is, the pasteboard identified by the UIPasteboardNameFind constant) is unavailable.

You must statically declare your app’s intended use of protected data classes by including the appropriate purpose string keys in your Info.plist file. For example, you must include the NSCalendarsUsageDescription key to access the user’s Calendar data. If you don’t include the relevant purpose string keys, your app exits when it tries to access the data.

iOS 10引入了几个更改和添加，可帮助您提高代码的安全性并维护用户数据的隐私。要了解有关这些项目的更多信息，请参见https://developer.apple.com/security/。

您的Info.plist文件的新的NSAllowsArbitraryLoadsInWebContent密钥为您提供了一种方便的方式来允许任意网页加载工作，同时为您的其他应用程序保留ATS保护。要了解有关此密钥的更多信息，请参阅NSAppTransportSecurity。

SecKey API包括对非对称密钥生成的改进。使用SecKey API，而不是不推荐的公共数据安全体系结构（CDSA）API。

所有SSL / TLS连接的RC4对称密码套件默认情况下都被禁用，Secure Transports API中不再支持SSLv3。建议您尽快停止使用SHA-1和3DES加密算法。

UIPasteboard类支持剪贴板功能，允许用户在设备之间复制和粘贴，并且包括可用于将粘贴板限制到特定设备的API，并设置过期时间戳，之后粘贴板被清除。另外，命名的粘贴板不再是持久的，而应该使用共享容器，而“查找”粘贴板（即由UIPasteboardNameFind常量标识的粘贴板）不可用。

您必须通过在Info.plist文件中包含适当的用途字符串键来静态声明应用程序对受保护数据类的预期用途。例如，您必须包含NSCalendarsUsageDescription键才能访问用户的日历数据。如果您不包括相关的目的字符串键，则当您的应用程序尝试访问数据时退出。

## 13.CallKit

The CallKit framework (CallKit.framework) lets VoIP apps integrate with the iPhone UI and give users a great experience. Use this framework to let users view and answer incoming VoIP calls on the lock screen and manage contacts from VoIP calls in the Phone app’s Favorites and Recents views.

CallKit also introduces app extensions that enable call blocking and caller identification. You can create an app extension that can associate a phone number with a name or tell the system when a number should be blocked.

CallKit框架（CallKit.framework）使VoIP应用程序与iPhone UI集成，并为用户提供了一个很好的体验。 使用此框架让用户在锁定屏幕上查看和应答传入的VoIP呼叫，并通过“电话”应用的“收藏夹”和“缩略图”视图管理来自VoIP呼叫的联系人。

CallKit还引入了支持呼叫阻止和呼叫者识别的应用程序扩展。 您可以创建一个可以将电话号码与名称相关联的应用程序扩展名，或者告诉系统何时应该阻止号码。

## 14.News Publisher Enhancements

新闻发布者增强

News Publisher makes it easy to deliver beautifully designed news, magazine, and web content to Apple News using the Apple News Format. Anyone can sign up, from major magazines or news organizations to independent publishers and bloggers. To get started or to learn more about recent updates, visit https://newsresources.apple.com.

新闻出版商可以轻松地使用苹果新闻格式向Apple News提供精美的新闻，杂志和网络内容。 任何人都可以从主要杂志或新闻机构注册到独立出版商和博主。 要开始使用或了解有关最新更新的更多信息，请访问https://newsresources.apple.com。

## 15.Video Subscriber Account

视频订阅者帐户

iOS 10 introduces the Video Subscriber Account framework (VideoSubscriberAccount.framework) to help apps that support authenticated streaming or authenticated video on demand (also known as TV Everywhere) authenticate with their cable or satellite TV provider. Using the APIs in this framework can help you support a single sign-in experience in which users sign in once to unlock access in all of the streaming video apps that their subscription supports.

iOS 10引入了视频订阅者帐户框架（VideoSubscriberAccount.framework），以帮助支持经过认证的流媒体或认证视频（也称为TV Everywhere）的应用程序与其有线或卫星电视提供商进行身份验证。 在此框架中使用API可以帮助您支持用户登录一次的单一登录体验，以解锁其订阅支持的所有流式视频应用程序的访问。

## 16.App Extensions

应用扩展

iOS 10 introduces several new extension points for which you can create an app extension, such as:

1. Call Directory

2. Intents

3. Intents UI

4. Messages

5. Notification Content

6. Notification Service

7. Sticker Pack

In addition, iOS 10 includes the following enhancements for third-party keyboard app extensions:

You can automatically detect the input language of a document by using the documentInputMode property of the UITextDocumentProxy class, and change your keyboard extension to align with that language (if supported). When you detect the input language in this way, you can do per-language keyboard switching such as what is built in to Messages.

The new handleInputModeListFromView:withEvent: method lets a keyboard extension display the system’s keyboard picker menu (that is, the globe key menu).

A keyboard extension should position the globe key in the same location as the system globe key for each orientation. Also, if you need to provide a custom key—to enable keyboard settings, for example—you should put this key in the same location as the dictation key in the system keyboard.

To learn more about creating app extensions in general, see App Extension Programming Guide.

iOS 10引入了几个新的扩展点，您可以为其创建应用程序扩展名，例如：

1. 呼叫目录

2. 意图

3. 意图UI

4. 消息

5. 通知内容

6. 通知服务

7. 贴纸包

此外，iOS 10还包含以下针对第三方键盘应用程序扩展功能的增强功能：

您可以使用UITextDocumentProxy类的documentInputMode属性来自动检测文档的输入语言，并更改键盘扩展以与该语言对齐（如果支持）。当您以这种方式检测输入语言时，您可以进行每语言键盘切换，例如内置于消息中的内容。

新的handleInputModeListFromView：withEvent：方法让键盘扩展显示系统的键盘选择器菜单（即全球关键菜单）。

键盘扩展应该将地球钥匙放置在与每个方向的系统地球仪相同的位置。另外，如果您需要提供自定义键 - 例如，启用键盘设置，您应该将该键放在与系统键盘中的听写键相同的位置。

要了解有关创建应用程序扩展的更多信息，请参阅App Extension编程指南。

## 17.Additional Framework Changes

额外的框架更改

In addition to the major changes described above, iOS 10 includes many other improvements.
除了上述主要变化之外，iOS 10还包括许多其他改进。

### 17.1 AVFoundation Camera Capture

The media capture subsystem in AVFoundation framework (AVFoundation.framework) includes several important changes.
Dual Camera and Device Discovery

iPhone 7 Plus includes a dual camera, which combines separate wide-angle and telephoto cameras that serve together as a single capture device. When using the dual camera device, iOS automatically uses either or both cameras based on light levels, zoom factor, and other conditions to capture the highest quality image possible. When you use the AVCaptureDevice class for video or photo capture, you can choose to use the dual camera device to gain these features, or to specifically use only the wide-angle or telephoto camera for more manual control.

To access capture devices in iOS 10.0 and later, you can use either of the following methods:

Call the defaultDeviceWithDeviceType:mediaType:position: method. (Pass the AVCaptureDeviceTypeBuiltInDuoCamera device type to access the dual camera. That call returns nil for devices without a dual camera—in that case, you can call the same method again, passing the AVCaptureDeviceTypeBuiltInWideAngleCamera device type, to obtain the default back camera.)

Create an AVCaptureDeviceDiscoverySession object, passing the device attributes you want to use for capture, and enumerate its devices list to select a device for your capture session.

Note: The AVCaptureDevice methods devices and devicesWithMediaType: are deprecated in iOS 10, and do not provide access to the dual camera or telephoto camera.

When you use the dual camera capture device, RAW capture and most manual controls are not available. To use these features, specifically select either the wide-angle or telephoto capture device. For details on the capabilities of each capture device, see iOS Device Compatibility Reference.
New Photo Capture API

The new AVCapturePhotoOutput class provides a unified pipeline for all photography workflows, enabling more sophisticated control and monitoring of the entire capture process and including support for new features such as Live Photos and RAW format capture. You should transition to AVCapturePhotoOutput instead of AVCaptureStillImageOutput, which is deprecated in iOS 10.
Wide Color

The Camera Capture pipeline now enables capture in wide-gamut color formats on supported hardware. By default, an AVCaptureSession automatically configures for wide-color capture when appropriate for your capture workflow—for details, see iOS Device Compatibility Reference.

AVFoundation框架（AVFoundation.framework）中的媒体捕获子系统包括几个重要的变化。
双摄像头和设备发现

iPhone 7 Plus包括一个双摄像头，它将单独的广角摄像头和长焦摄像头组合在一起，作为单个捕获设备。当使用双摄像头设备时，iOS会根据光线水平，缩放因子和其他条件自动使用两个或两个摄像机，以捕获最高质量的图像。当您使用AVCaptureDevice类进行视频或照片捕获时，您可以选择使用双摄像头设备获得这些功能，或者仅专门使用广角摄像机或长焦摄像机进行更多手动控制。

要在iOS 10.0及更高版本中访问捕获设备，可以使用以下任一方法：

调用defaultDeviceWithDeviceType：mediaType：position：method。 （通过AVCaptureDeviceTypeBuiltInDuoCamera设备类型以访问双摄像头，该通话对于没有双摄像头的设备返回零） - 在这种情况下，您可以再次调用相同的方法，传递AVCaptureDeviceTypeBuiltInWideAngleCamera设备类型，以获取默认的后置摄像头。）

创建AVCaptureDeviceDiscoverySession对象，传递要用于捕获的设备属性，并枚举其设备列表以选择捕获会话的设备。

注意：AVCaptureDevice方法的设备和设备WithMediaType：在iOS 10中已被弃用，并且不提供对双摄像头或长焦摄像头的访问。

当您使用双摄像头捕获设备时，RAW捕获和大多数手动控制都不可用。要使用这些功能，请特别选择广角或长焦拍摄装置。有关每个捕获设备的功能的详细信息，请参阅iOS设备兼容性参考。
新的Photo Capture API

新的AVCapturePhotoOutput类为所有摄影工作流程提供了统一的管道，可以对整个捕获过程进行更加复杂的控制和监控，并包括对Live Photos和RAW格式捕获等新功能的支持。您应该转换到AVCapturePhotoOutput而不是AVCaptureStillImageOutput，这在iOS 10中已被弃用。
宽颜色

相机捕捉管道现在可以在支持的硬件上以宽色域颜色格式捕获。默认情况下，AVCaptureSession在适合捕获工作流程时自动配置为广泛捕获，有关详细信息，请参阅iOS设备兼容性参考。

### 17.2 AVFoundation Media

The media playback and editing subsystem in AVFoundation framework (AVFoundation.framework) includes the following enhancements:

You no longer need to implement different behaviors for AVPlayerItem, depending on whether the content is a movie file or HLS content. In apps that link on or after iOS 10, you simply set the rate property and AVFoundation determines when enough content has been buffered to play without stalling.

The AVPlayerLooper class makes it easier to loop a particular piece of media content during playback.

Use the AVAssetDownloadURLSession class to download an asset, including an HLS stream, to the device and then play it later. When used in conjunction with FairPlay Streaming, you can download an encrypted HLS stream and play the stream securely at a later time.

AVFoundation框架（AVFoundation.framework）中的媒体播放和编辑子系统包括以下增强功能：

您不再需要为AVPlayerItem实现不同的行为，具体取决于内容是电影文件还是HLS内容。 在iOS 10之间或之后连接的应用程序中，您只需设置速率属性，AVFoundation就可以确定何时有足够的内容被缓冲播放而不停顿。

AVPlayerLooper类可以在播放过程中更容易地循环播放特定的媒体内容。

使用AVAssetDownloadURLSession类将资产（包括HLS流）下载到设备，然后稍后再播放。 当与FairPlay Streaming一起使用时，您可以下载加密的HLS流，并在以后安全地播放流。

### 17.3 AVKit

The AVKit framework (AVKit.framework) includes the updatesNowPlayingInfoCenter property, which indicates when the Now Playing Info Center should be updated.

AVKit框架（AVKit.framework）包含updatesNowPlayingInfoCenter属性，该属性指示正在播放信息中心何时更新。

### 17.4 Core Data

The Core Data framework (CoreData.framework) includes the following enhancements:

NSPersistentStoreCoordinator now maintains a connection pool for SQLite stores. Root NSManagedObjectContext objects (those without parent MOCs) transparently support concurrent fetching and faulting without serializing against each other.

NSManagedObjectContext objects with SQLite stores in WAL journal_mode support a new feature called query generations. These allow a MOC to be pinned to a version of the database at a point in time and perform all future fetching and faulting against that version of the database. Pinned MOCs are moved to the most recent transaction with any save, and query generations do not survive the process's life time.

The new NSPersistentContainer class provides your app with a high-level integration point that maintains references to your NSPersistentStoreCoordinator, NSManagedObjectModel, and other configuration resources.

Core Data now has tighter integration with Xcode and automatically generates and updates your NSManagedObject subclasses.

NSManagedObject includes several additional convenience methods, making it easier to fetch and create subclasses. NSManagedObject subclasses that have a 1:1 relationship with an entity now support entity.

Core Data introduces several API adjustments that provide better integration with Swift, including parameterized NSFetchRequest objects.

For more information, see Core Data Framework Reference.

Core Data框架（CoreData.framework）包括以下增强功能：

NSPersistentStoreCoordinator现在维护SQLite存储的连接池。根NSManagedObjectContext对象（没有父MOC的对象）透明地支持并发获取和错误，而不会相互序列化。

带有SQLite存储的NSManagedObjectContext对象在WAL journal_mode中支持称为查询代的新功能。这些允许在某个时间点将MOC固定到数据库的版本，并执行所有未来的数据库版本的提取和故障。固定的MOC被移动到最新的事务，任何保存，并且查询世代不能存活过程的生命。

新的NSPersistentContainer类为您的应用提供了一个高级集成点，可以保持对NSPersistentStoreCoordinator，NSManagedObjectModel和其他配置资源的引用。

核心数据现在与Xcode更紧密的集成，并自动生成和更新您的NSManagedObject子类。

NSManagedObject包含几个其他方便的方法，使得它更容易获取和创建子类。与实体具有1：1关系的NSManagedObject子类现在支持实体。

Core Data引入了几个API调整，可以与Swift进行更好的集成，包括参数化的NSFetchRequest对象。

有关更多信息，请参阅核心数据框架参考。

### 17.5 Core Image

The Core Image framework (CoreImage.framework) includes several enhancements.

RAW image file support is now available on iOS devices that use the A8 or A9 CPU. Core Image can decode RAW images produced by several third-party cameras as well as images produced by the iSight camera of supported iOS devices (to learn more, see AVFoundation). To process RAW images, use filterWithImageData:options: or filterWithImageURL:options: to create a CIFilter object, adjust RAW processing options with the keys listed in RAW Image Options, and read the processed image from the filter’s outputImage property.

You can now insert custom processing into a Core Image filter graph by using the imageWithExtent:processorDescription:argumentDigest:inputFormat:outputFormat:options:roiCallback:processor: method. This method adds a callback block that Core Image invokes in between filters when processing an image for display or output; in the block, you can access the pixel buffers or Metal textures containing the current state of the processed image and apply your own image processing algorithms.

When using a custom processor block or writing filter kernels, you can process images in a color space other than the Core Image context’s working color space. Use the imageByColorMatchingWorkingSpaceToColorSpace: and imageByColorMatchingColorSpaceToWorkingSpace: methods to convert into and out of your color space before and after processing.

Performance is significantly improved for rendering UIImage objects that are backed by Core Image images (such as those created by using the initWithCIImage: initializer) in a UIImageView object. In addition, a Core Image–backed UIImage object that’s tagged with a wide-gamut color profile renders in a UIImageView object that uses wide-gamut color (on capable iOS devices).

Core Image kernel code can now request a specific output pixel format.

Core Image introduces five new filters:

CINinePartTiled

CINinePartStretched

CIHueSaturationValueGradient

CIEdgePreserveUpsampleFilter

CIClamp

Core Image框架（CoreImage.framework）包含几个增强功能。

现在可以在使用A8或A9 CPU的iOS设备上使用RAW图像文件支持。核心图像可以解码多个第三方摄像机生成的RAW图像以及由支持的iOS设备的iSight摄像机生成的图像（了解更多信息，请参阅AVFoundation）。要处理RAW图像，请使用filterWithImageData：options：或filterWithImageURL：options：创建CIFilter对象，使用RAW Image Options中列出的键调整RAW处理选项，并从过滤器的outputImage属性读取已处理的图像。

现在可以使用imageWithExtent将参数插入到Core Image过滤器图中：processorDescription：argumentDigest：inputFormat：outputFormat：options：roiCallback：processor：method。该方法在处理用于显示或输出的图像时，添加Core Image在过滤器之间调用的回调块;在块中，您可以访问包含处理后图像的当前状态的像素缓冲区或金属纹理，并应用自己的图像处理算法。

使用自定义处理器块或编写过滤器内核时，可以处理除Core Image上下文的工作颜色空间之外的颜色空间中的图像。使用imageByColorMatchingWorkingSpaceToColorSpace：和imageByColorMatchingColorSpaceToWorkingSpace：在处理之前和之后转换成颜色空间的方法。

在UIImageView对象中渲染由Core Image映像（例如使用initWithCIImage：initializer创建的那些）支持的UIImage对象，性能显着提高。另外，使用宽色域颜色配置文件标记的Core Image-Support UIImage对象呈现在使用宽色域颜色的UIImageView对象（在有能力的iOS设备上）。

Core Image内核代码现在可以请求特定的输出像素格式。

Core Image引入了五个新的过滤器：

CINinePartTiled

CINinePartStretched

CIHueSaturationValueGradient

CIEdgePreserveUpsampleFilter

CIClamp

### 17.6 Core Motion

The Core Motion framework (CoreMotion.framework) includes pedometer events, which enable apps to receive fast real-time notifications when users pause and resume while running. On supported devices, apps can use CMPedometer APIs to register to receive live pedometer events while running in the foreground or the background.

Core Motion框架（CoreMotion.framework）包括计步器事件，当用户在运行时暂停和恢复时，可使应用程序接收快速实时通知。 在受支持的设备上，应用程序可以使用CMPedometer API进行注册，以便在前台或后台运行时接收实时计步器事件。

### 17.7 Foundation

The Foundation framework (Foundation.framework) contains many enhancements, such as:

The new NSDateInterval class defines a programmatic interface for calculating the duration of a time interval and determining whether a date falls within it, as well as comparing date intervals and checking to see whether they intersect.

The NSLocale class defines many new properties that you can use to get information about a locale and how it can be displayed.

The new NSMeasurement class helps you convert measurements into different units, and calculate the sum or difference between two measurements. The new NSMeasurementFormatter class helps you create localized representations of measurements when displaying quantities of units to the user.

The new NSUnit class and concrete NSDimension subclasses help you represent specific units of measure.

基础框架（Foundation.framework）包含许多增强功能，如：

新的NSDateInterval类定义了一个编程接口，用于计算时间间隔的持续时间，并确定一个日期是否落在其中，以及比较日期间隔并检查它们是否相交。

NSLocale类定义了许多新的属性，可用于获取有关区域设置的信息以及如何显示。

新的NSMeasurement类可以帮助您将测量值转换为不同的单位，并计算两次测量之间的总和或差值。 新的NSMeasurementFormatter类可以帮助您在向用户显示单位数量时，创建测量的局部化表示。

新的NSUnit类和具体的NSDimension子类可帮助您表示特定的度量单位。

### 17.8 GameKit

The GameKit framework (GameKit.framework) includes the following changes and enhancements:

The Game Center app has been removed. If your game implements GameKit features, it must also implement the interface behavior necessary for the user to see these features. For example, if your game supports leaderboards, it could present a GKGameCenterViewController object or read the data directly from Game Center to implement a custom user interface.

A new account type, implemented by the GKCloudPlayer class, supports iCloud-only game accounts.

Game Center provides a new generalized solution for managing persistent storage of data on Game Center. A game session (GKGameSession) has a list of players who are the session’s participants. Your game’s implementation defines when and how a participant stores or retrieves data from the server or exchanges data between players. Game sessions can often replace existing turn-based matches, real-time matches, and persistent save games, and also enable other models of interaction between participants.

GameKit框架（GameKit.framework）包括以下更改和增强功能：

游戏中心应用已被删除。如果您的游戏实现了GameKit功能，它还必须实现用户看到这些功能所需的界面行为。例如，如果您的游戏支持排行榜，它可以呈现一个GKGameCenterViewController对象，或直接从Game Center读取数据来实现自定义用户界面。

由GKCloudPlayer类实现的新帐户类型支持仅限iCloud的游戏帐户。

游戏中心提供了一个新的通用解决方案，用于管理Game Center中数据的持久存储。游戏会话（GKGameSession）有一个参赛者名单。游戏的实现定义了参与者从服务器存储或检索数据的时间和方式，或者在玩家之间交换数据。游戏会话通常可以取代现有的基于回合制的比赛，实时比赛和永久保存游戏，并且还可以使参与者之间的其他交互模式。

### 17.9 GameplayKit

The GameplayKit framework (GameplayKit.framework) includes the following changes and enhancements:

Procedural noise generation can be used to generate rich game worlds, create sophisticated natural-looking textures, and add realism to camera movement.

Spatial partitioning lets you partition your game world data so that the data in the game world can be searched efficiently.

A new Monte Carlo strategist (GKMonteCarloStrategist) helps you model games where exhaustive computation of possible moves is difficult.

The new decision tree API can enhance your game-building AI when you adopt decision-tree learning to generalize behavior based on data mining of logged player actions. To learn more, see GKDecisionTree and GKDecisionNode.

The GKAgent3D and GKGraphNode3D classes introduce 3D support to existing agent and path-finding behavior.

The new GKMeshGraph class provides a higher performance alternative to GKObstacleGraph, allowing you to produce more natural-looking output at the cost of less mathematically perfect paths.

The new GKScene and GKSKNodeComponent classes, combined with changes in SpriteKit and the Xcode editor, make integrating GameplayKit with SpriteKit easier than ever.

GameplayKit框架（GameplayKit.framework）包括以下更改和增强功能：

程序性噪声产生可用于产生丰富的游戏世界，创造出复杂的自然风格的纹理，并增加了相机运动的现实感。

空间分区可让您分割游戏世界的数据，以便能够有效地搜索游戏世界中的数据。

一个新的蒙特卡洛策略师（GKMonteCarloStrategist）帮助您模拟可能的动作穷尽计算的游戏。

当您采用决策树学习来根据记录的玩家行为的数据挖掘推广行为时，新的决策树API可以增强您的游戏制作AI。要了解更多信息，请参阅GKDecisionTree和GKDecisionNode。

GKAgent3D和GKGraphNode3D类向现有代理和路径查找行为引入了3D支持。

新的GKMeshGraph类为GKObstacleGraph提供了更高性能的替代品，让您以更少的数学完美路径为代价，生产出更自然的输出。

新的GKScene和GKSKNodeComponent类与SpriteKit和Xcode编辑器的更改结合在一起，使得集成GameplayKit与SpriteKit比以往更加容易。


### 17.10 HealthKit

The HealthKit framework (HealthKit.framework) includes the following changes and enhancements:

The new HKCDADocument class, which represents a CDA document (that is, a document that follows the Clinical Document Architecture standard).

The new HKWorkoutConfiguration class, which lets you specify the activityType and locationType for a workout.

The new HKWheelchairUseObject characteristic object type and the related HKHealthStore method wheelchairUseWithError:.

New metadata keys that indicate weather types, such as HKWeatherConditionClear and HKWeatherConditionCloudy, and workout types, such as HKWorkoutActivityTypeFlexibility and HKWorkoutActivityTypeWheelchairRunPace.

HealthKit框架（HealthKit.framework）包含以下更改和增强功能：

新的HKCDADocument类代表CDA文件（即遵循临床文件架构标准的文件）。

新的HKWorkoutConfiguration类可以让您指定一个锻炼的activityType和locationType。

新的HKWheelchairUseObject特征对象类型和相关的HKHealthStore方法WheelchairUseWithError :.

指示天气类型的新元数据键，例如HKWeatherConditionClear和HKWeatherConditionCloudy，以及锻炼类型，例如HKWorkoutActivityTypeFlexibility和HKWorkoutActivityTypeWheelchairRunPace。

### 17.11 HomeKit

In iOS 10, iPad can be configured to provide remote access to accessories, run automation triggers, and enable shared user permissions. In addition, the HomeKit framework (HomeKit.framework) adds support for camera and doorbell accessories and introduces many new APIs that help you:

View and interact with IP camera accessory profiles, display live streams and snapshots, and control a camera’s settings, speaker, and microphone

Access new services and characteristics

For the primary service, link services and valid values to provide more context and configuration about the accessories

You can also add and set up accessories using the Apple accessory setup workflow. To learn more, see HomeKit Framework Reference.

在iOS 10中，iPad可以配置为提供远程访问附件，运行自动化触发器和启用共享用户权限。 此外，HomeKit框架（HomeKit.framework）增加了对相机和门铃配件的支持，并引入了许多新的API来帮助您：

查看和互动IP摄像机附件配置文件，显示实况流和快照，并控制摄像机的设置，扬声器和麦克风

获取新的服务和特点

对于主要服务，链接服务和有效值，以提供有关附件的更多上下文和配置

您还可以使用Apple附件设置工作流程添加和设置配件。 要了解更多信息，请参阅HomeKit框架参考。

### 17.12 Metal

In iOS 10, Metal includes several new features and enhancements, such as:

Support for tessellation, enabling 3D apps and games to render more detailed scenes by efficiently describing complex geometry to the GPU.

Function Specialization, which makes it easy to create a collection of highly optimized functions to handle all the material and light combinations in a scene.

Resource Heaps and Memoryless Render Targets, which grant even finer-grained control of resource allocation to further optimize the performance of Metal-based apps.

To learn more, see What’s New in iOS 10, tvOS 10, and OS X 10.12 in Metal Programming Guide.

在iOS 10中，Metal包含了几项新功能和增强功能，如：

支持细分，使3D应用程序和游戏能够通过有效地描述GPU的复杂几何图形来渲染更详细的场景。

功能专业化，可以轻松创建高度优化的功能集，以处理场景中的所有材质和光线组合。

资源堆和无记忆渲染目标，使资源分配更加细粒度的控制，以进一步优化基于金属的应用程序的性能。

要了解更多信息，请参阅“金属编程指南”中的iOS 10，tvOS 10和OS X 10.12中的新功能。

### 17.13 ModelIO

The ModelIO framework (ModelIO.framework) includes the following enhancements:

The USD file format is now supported.

The new MDLMaterialPropertyGraph class makes it easier to support runtime procedural changes to models.

The MDLVoxelArray class adds support for signed distance fields.

You can add assisted light probe placement by implementing the MDLLightProbeIrradianceDataSource protocol.

ModelIO框架（ModelIO.framework）包括以下增强功能：

现在支持USD文件格式。

新的MDLMaterialPropertyGraph类使得更容易支持模型的运行时过程更改。

MDLVoxelArray类增加了对已签名距离字段的支持。

您可以通过实施MDLLightProbeIrradianceDataSource协议来添加辅助光探针放置。

### 17.14 Photos

The Photos framework (Photos.framework) makes Live Photo editing available to apps that use Photos framework APIs to access the user's Photos library and to photo editing app extensions for use in the Photos and Camera apps. Specifically, the new PHLivePhotoEditingContext class lets you apply edits to the video and still photo content of a Live Photo, with an easy-to-use API based on Core Image enhancements. In addition, you can take advantage of the new Core Image processor feature to use other image processing technologies to perform edits. To learn more, see CIImageProcessorInput and CIImageProcessorOutput.

照片框架（Photos.framework）使实时照片编辑可用于使用Photos框架API的应用程序来访问用户的照片库和用于照片和相机应用程序的照片编辑应用程序扩展。 具体来说，新的PHLivePhotoEditingContext类允许您使用基于Core Image增强功能的易于使用的API对实时照片的视频和静态照片内容进行编辑。 此外，您可以利用新的Core Image处理器功能使用其他图像处理技术来执行编辑。 要了解更多信息，请参阅CIImageProcessorInput和CIImageProcessorOutput。

### 17.15 ReplayKit

The ReplayKit framework (ReplayKit.framework) includes the following enhancements:

ReplayKit supports broadcasting services so that a user can broadcast recorded media through a third-party site. You can implement support for this functionality by using the RPScreenRecorder, RPBroadcastActivityViewController, and RPBroadcastController classes.

To participate in ReplayKit broadcast, third-party broadcast services need to implement a pair of app extensions. The Broadcast UI extension provides a UI that lets users sign into the service and set up a broadcast. The Broadcast Upload extension receives movie clips and transmits them to the service.

ReplayKit框架（ReplayKit.framework）包括以下增强功能：

ReplayKit支持广播服务，以便用户可以通过第三方站点广播录制的媒体。 您可以通过使用RPScreenRecorder，RPBroadcastActivityViewController和RPBroadcastController类实现对此功能的支持。

要参与ReplayKit广播，第三方广播服务需要实现一对应用程序扩展。 Broadcast UI扩展提供了一个用户界面，可以让用户登录服务并设置广播。 广播上传分机接收电影剪辑并将其发送到服务。

### 17.16 SceneKit

The SceneKit framework (SceneKit.framework) includes several enhancements.

A new Physically Based Rendering (PBR) system allows you to leverage the latest in 3D graphics research to create more realistic results with simpler asset authoring. Specifically:

Use the new SCNLightingModelPhysicallyBased shading model to opt into PBR shading for materials. PBR materials require only three fundamental properties—diffuse, metalness, and roughness—to produce a wide range of realistic shading effects. (The normal, ambientOcclusion, and selfIllumination material properties also remain useful for PBR materials, but you can now ignore the large number of other properties used for traditional materials.)

PBR shading works best with environment-based lighting, which causes even diffuse surfaces to pick up the colors of the scene around them. Use the lightingEnvironment property to assign global image-based lighting to an entire scene, and place light probes in the Xcode scene editor to pick up the local lighting contributions from objects within your scene.

Authors of PBR scene content often prefer working in physically based terms, so you can now define lighting using intensity (in lumens) and color temperature (in degrees Kelvin), and import specifications for real-world light fixtures using the IESProfileURL property.

Add even more realism with the new HDR features and effects in the SCNCamera class. With HDR rendering, SceneKit captures a much wider range of brightness and contrast in a scene, then allows you to customize the tone mapping that adapts that scene for the narrower range of a device’s display. Enable exposure adaptation to create automatic effects when, for example, the player in your game moves from a darkened area into sunlight. Or use vignetting, color fringing, and color grading to add a filmic look to your game.

Although linear, more color-accurate rendering is the basis for PBR shading and HDR camera features, it produces better results even for traditional rendering. By default, SceneKit now performs all color calculations in a linear (not gamma-adjusted) color space, and uses the P3 color gamut of devices that include wide-color displays. This feature is enabled automatically for all apps linking against the iOS 10 SDK, and has a few ramifications for content design and asset management:

SceneKit color matches all colors. In previous versions, SceneKit would read only the color values from material colors specified as NSColor or UIColor objects, ignoring color profile information and assuming the sRGB color space.

SceneKit interprets color component values specified within shader modifier or custom Metal or OpenGL shader code in linear RGB space.

SceneKit reads and adjusts for color profile information in texture images. Design textures for a linear brightness ramp, and use Asset Catalogs in Xcode to make sure your images use the correct color profile.

If necessary, you can disable linear space rendering with the SCNDisableLinearSpaceRendering key in your app’s Info.plist file, and wide color rendering with the SCNDisableWideGamut key.

Geometry can now be loaded from scene files or programmatically defined using arbitrary polygon primitives (SCNGeometryPrimitiveTypePolygon). SceneKit automatically triangulates polygon meshes for rendering, but makes use of the underlying polygon mesh for more accurate surface subdivision (to learn more, see the subdivisionLevel property).

SceneKit框架（SceneKit.framework）包含几个增强功能。

新的基于物理的渲染（PBR）系统允许您利用最新的3D图形研究，以更简单的资产创作创建更逼真的结果。特别：

使用新的SCNLightingModelPhysicallyBased着色模型选择材料的PBR阴影。 PBR材料只需要三个基本性质 - 漫射，金属和粗糙度 - 产生广泛的真实阴影效果。 （正常，环境消除和自发光材料属性对于PBR材料仍然有用，但现在您可以忽略大量用于传统材料的其他性能。）

PBR阴影最适合基于环境的照明，这导致均匀的漫射表面拾取它们周围的场景的颜色。使用lightingEnvironment属性将全局基于图像的照明分配给整个场景，并将光探测器放置在Xcode场景编辑器中，以从场景中的对象拾取本地照明的贡献。

PBR场景内容的作者通常喜欢在物理方面工作，因此您现在可以使用强度（流明）和色温（开氏度）定义照明，并使用IESProfileURL属性导入真实灯具的导入规格。

在SCNCamera类中添加新的HDR功能和效果更加逼真。通过HDR渲染，SceneKit可以在场景中捕获更宽范围的亮度和对比度，然后允许您自定义适应场景的色调映射，从而缩小设备显示范围。当您的游戏中的玩家从黑暗的地方移动到阳光下时，启用曝光适应以创建自动效果。或者使用渐晕，彩色条纹和颜色分级，为您的游戏添加电影。

虽然线性，色彩更准确的渲染是PBR阴影和HDR相机功能的基础，但即使对于传统渲染也能产生更好的效果。默认情况下，SceneKit现在可以在线性（而不是伽玛调整）的颜色空间中执行所有颜色计算，并使用包含宽色显示的设备的P3色域。对于与iOS 10 SDK连接的所有应用，此功能都自动启用，并且对内容设计和资产管理有一些后果：

SceneKit颜色匹配所有颜色。在以前的版本中，SceneKit将仅读取指定为NSColor或UIColor对象的材质颜色的颜色值，忽略颜色配置文件信息并假设sRGB颜色空间。

SceneKit解释着色器修饰符中指定的颜色分量值或线性RGB空间中的自定义金属或OpenGL着色器代码。

SceneKit读取并调整纹理图像中的颜色配置文件信息。为线性亮度斜坡设计纹理，并在Xcode中使用资产目录，以确保您的图像使用正确的颜色配置文件。

如果需要，您可以使用应用程序Info.plist文件中的SCNDisableLinearSpaceRendering键禁用线性空间渲染，并使用SCNDisableWideGamut键进行宽显色。

现在可以从场景文件加载几何图形，或者使用任意多边形基元（SCNGeometryPrimitiveTypePolygon）以编程方式定义几何。 SceneKit自动将多边形网格三角形进行渲染，但是使用底层多边形网格可以更准确地进行表面细分（要了解更多信息，请参阅subdivisionLevel属性）。

### 17.17 SpriteKit

The SpriteKit framework (SpriteKit.framework) includes the following enhancements:

A new tilemap solution supports square, hexagonal, and isometric tilemaps that make it easy to create 2D, 2.5D, and side-scroller games. The Xcode editor provides comprehensive support for organizing your tiles and creating your tilemap. For more information, see the SKTileMapNode, SKTileGroup, SKTileGroupRule, and SKTileSet classes .

The new SKWarpGeometry class is used to stretch or distort how a SKSpriteNode or SKEffectNode object is rendered. The warp is specified by a set of control points. New SKAction types can be used to animate between different warp effects.

A custom shader can use attributes that can be configured separately by each node that uses the shader. To add an attribute, create an SKAttribute object and attach it to your shader. Then, for each node that uses that shader, attach an SKAttributeValue object.]

The SKView class defines new methods that give you finer control over when and how your scene is rendered.

SpriteKit框架（SpriteKit.framework）包括以下增强功能：

一个新的tilemap解决方案支持方形，六边形和等距图形，可以轻松创建2D，2.5D和侧面滚动游戏。 Xcode编辑器提供了组织瓦片和创建瓦片贴图的全面支持。有关更多信息，请参阅SKTileMapNode，SKTileGroup，SKTileGroupRule和SKTileSet类。

新的SKWarpGeometry类用于扩展或扭曲SKSpriteNode或SKEffectNode对象的呈现方式。翘曲由一组控制点指定。新的SKAction类型可用于在不同的翘曲效果之间进行动画化。

自定义着色器可以使用可以由使用着色器的每个节点单独配置的属性。要添加属性，请创建一个SKAttribute对象并将其附加到着色器。然后，对于使用该着色器的每个节点，请附加一个SKAttributeValue对象。

SKView类定义了新的方法，可以更好地控制场景的渲染时间和方式。

### 17.18 UIKit

The UIKit framework (UIKit.framework) includes many enhancements, such as:

New object-based, fully interactive and interruptible animation support that lets you retain control of your animations and link them with gesture-based interactions. To learn more, see UIViewAnimating Protocol Reference, UIViewPropertyAnimator Class Reference, UITimingCurveProvider Protocol Reference, UICubicTimingParameters Class Reference, and UISpringTimingParameters Class Reference.

The new UIPreviewInteraction class and UIPreviewInteractionDelegate protocol, which let you provide a custom user interface related to the peek and pop experience.

The new UIAccessibilityCustomRotor class and related classes that help you provide custom, context-specific functionality that assistive technologies such as VoiceOver can expose to users. For example, you might create a custom rotor that lets VoiceOver users find misspelled words in a document by repeatedly returning the range of text that contains the next misspelled word.

The UIAccessibilityIsAssistiveTouchRunning and UIAccessibilityAssistiveTouchStatusDidChangeNotification symbols, which let you determine when AssistiveTouch is enabled, and the UIAccessibilityHearingDevicePairedEar and UIAccessibilityHearingDevicePairedEarDidChangeNotification symbols, which give you the pairing status of MFi hearing aids.

New UIPasteboard API that automatically declares compatible content types for common class instances and new options that limit the lifetime of objects on the pasteboard.

New options in UIPasteboard

The new preferredFontForTextStyle:compatibleWithTraitCollection: UIFont method, which lets you add support for Dynamic Type in labels, text fields, and other text areas.

The UIContentSizeCategoryAdjusting protocol, which provides the adjustsFontForContentSizeCategory property that you can use to determine if the adopting element should update its font when the device’s UIContentSizeCategory changes.

Additional control over the appearance of the badge on a tab bar item, such as background color and text attributes.

Support for the refresh control in all scroll views and scroll-view subclasses, such as UICollectionView.

The new UIApplication method openURL:options:completionHandler:, which is executed asynchronously and calls the specified completion handler on the main queue (this method replaces openURL:).

The new UICloudSharingController class and UICloudSharingControllerDelegate protocol, which help you initiate a CloudKit sharing operation and display a view controller that lets users view and modify participants and start and stop sharing.

Enhancements to UICollectionView and the new UICollectionViewDataSourcePrefetching protocol, which help you take advantage of automatic prefetching of cells to improve the scrolling experience.

UIKit框架（UIKit.framework）包含许多增强功能，如：

新的基于对象的完全交互式和可中断的动画支持，可让您保留对动画的控制，并将其与基于手势的交互链接。要了解更多信息，请参阅UIViewAnimating Protocol Reference，UIViewPropertyAnimator类参考，UITimingCurveProvider协议参考，UICubicTimingParameters类参考和UISpringTimingParameters类参考。

新的UIPreviewInteraction类和UIPreviewInteractionDelegate协议，让您提供与偷窥和流行体验相关的自定义用户界面。

新的UIAccessibilityCustomRotor类和相关类可帮助您提供自定义的上下文相关功能，辅助技术（如VoiceOver）可以向用户展示。例如，您可以创建一个自定义转子，让VoiceOver用户通过重复返回包含下一个拼写错误的单词的文本范围，在文档中找到拼写错误的单词。

UIAccessibilityIsAssistiveTouchRunning和UIAccessibilityAssistiveTouchStatusDidChangeNotification符号，让您确定何时启用AssistiveTouch以及UIAccessibilityHearingDevicePairedEar和UIAccessibilityHearingDevicePairedEarDidChangeNotification符号，这些符号为您提供了MFi助听器的配对状态。

新的UIPasteboard API可以自动声明普通类实例的兼容内容类型和限制粘贴板上对象生命周期的新选项。

UIPasteboard中的新选项

新的preferredFontForTextStyle：compatibleWithTraitCollection：UIFont方法，它允许您在标签，文本字段和其他文本区域中添加对动态类型的支持。

UIContentSizeCategoryAdjusting协议提供adjustFontForContentSizeCategory属性，可用于确定在设备的UIContentSizeCategory更改时采用元素是否应更新其字体。

额外控制标签栏项目上徽章的外观，如背景颜色和文本属性。

支持所有滚动视图和滚动视图子类（如UICollectionView）中的刷新控件。

新的UIApplication方法openURL：options：completionHandler :,它是异步执行的，并在主队列上调用指定的完成处理程序（此方法将替换openURL :)。

新的UICloudSharingController类和UICloudSharingControllerDelegate协议，可帮助您启动CloudKit共享操作并显示视图控制器，允许用户查看和修改参与者并启动和停止共享。

增强UICollectionView和新的UICollectionViewDataSourcePrefetching协议，帮助您利用单元格的自动预取来改善滚动体验。

### 17.19 WebKit

The WebKit framework (WebKit.framework) introduces enhanced peek and pop support in WKWebView objects. In iOS 10, you can use the webView:shouldPreviewElement: method to determine if the specified web view should display the preview.

WebKit框架（WebKit.framework）在WKWebView对象中引入了增强的窥视和弹出支持。 在iOS 10中，您可以使用webView：shouldPreviewElement：方法来确定指定的Web视图是否应显示预览。

## 18.Deprecated APIs

iOS 10 deprecates several APIs, including:

The CloudKit CKDiscoverAllContactsOperation, CKDiscoveredUserInfo, CKDiscoverUserInfosOperation, CKFetchRecordChangesOperation classes. Instead, use CKDiscoverAllUserIdentitiesOperation, CKUserIdentity, CKDiscoverUserIdentitiesOperation, and CKFetchRecordZoneChangesOperation classes, all of which support record sharing.

Several CKSubscription APIs, such as methods and properties related to zone-based subscriptions (use CKRecordZoneSubscription APIs instead) and to query-based subscriptions (use CKQuerySubscription APIs instead).

Several NSPersistentStoreCoordinator symbols related to ubiquitous content.

The ADBannerView and ADInterstitialAd classes and related symbols in UIViewController.

Several SKUniform symbols related to floating point values. Instead, use methods such as initWithName:vectorFloat2: and uniformWithName:matrixFloat2x2:, as appropriate.

Several UIKit classes related to notifications, such as UILocalNotification, UIMutableUserNotificationAction, UIMutableUserNotificationCategory, UIUserNotificationAction, UIUserNotificationCategory, and UIUserNotificationSettings. Use APIs in the User Notifications framework instead (see User Notifications Framework Reference).

The handleActionWithIdentifier:forLocalNotification:, handleActionWithIdentifier:forRemoteNotification:, didReceiveLocalNotification:withCompletion:, and didReceiveRemoteNotification:withCompletion: WatchKit methods. Use handleActionWithIdentifier:forNotification: and didReceiveNotification:withCompletion: instead.

Also the notification-handling methods in WKExtensionDelegate, such as didReceiveRemoteNotification: and handleActionWithIdentifier:forRemoteNotification:. Instead of using these methods, first create a delegate object that adopts the UNUserNotificationCenterDelegate protocol and implement the appropriate methods. Then assign the delegate object to the delegate property of the singleton UNUserNotificationCenter object. 

For a complete list of specific API deprecations, see iOS 10.0 API Diffs.


iOS 10不推荐使用多种API，其中包括：

CloudKit CKDiscoverAllContactsOperation，CKDiscoveredUserInfo，CKDiscoverUserInfosOperation，CKFetchRecordChangesOperation类。而是使用CKDiscoverAllUserIdentitiesOperation，CKUserIdentity，CKDiscoverUserIdentitiesOperation和CKFetchRecordZoneChangesOperation类，所有这些类都支持记录共享。

几个CKSubscription API，例如与基于区域的订阅相关的方法和属性（使用CKRecordZoneSubscription API）和基于查询的订阅（使用CKQuerySubscription API代替）。

几个与普遍存在的内容相关的NSPersistentStoreCoordinator符号。

在UIViewController中的ADBannerView和ADInterstitialAd类和相关符号。

与浮点值相关的若干SKUniform符号。而是酌情使用initWithName：vectorFloat2和uniformWithName：matrixFloat2x2：的方法。

与通知相关的若干UIKit类，例如UILocalNotification，UIMutableUserNotificationAction，UIMutableUserNotificationCategory，UIUserNotificationAction，UIUserNotificationCategory以及UIUserNotificationSettings。在用户通知框架中使用API​​（请参阅用户通知框架参考）。

handleActionWithIdentifier：forLocalNotification :, handleActionWithIdentifier：forRemoteNotification :, didReceiveLocalNotification：withCompletion :, did didReceiveRemoteNotification：withCompletion：WatchKit方法。使用handleActionWithIdentifier：forNotification：and didReceiveNotification：withCompletion：而不是。

还有在WKExtensionDelegate中的通知处理方法，如didReceiveRemoteNotification：和handleActionWithIdentifier：forRemoteNotification :.而不是使用这些方法，首先创建一个委托对象，该对象采用UNUserNotificationCenterDelegate协议并实现适当的方法。然后将委托对象分配给单例UNUserNotificationCenter对象的delegate属性。

有关特定API弃用的完整列表，请参阅iOS 10.0 API差异。

